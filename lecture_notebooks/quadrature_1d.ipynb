{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finite element method requires computing certain integrals, for example, in the right-hand side, there are integrals of the form\n",
    "$$\n",
    "    \\int f(x) \\phi_i(x) \\, dx\n",
    "$$\n",
    "and in the stiffness matrix, there are integrals of the form\n",
    "$$\n",
    "    \\int \\phi_i'(x) \\phi_j'(x) \\, dx.\n",
    "$$\n",
    "In these expression expression, $\\phi_i$ represents a basis function.\n",
    "We have seen piecewise linear basis functions; more generally, we can consider piecewise polynomial basis functions.\n",
    "Simple closed-form expressions for integrals of these functions (and their derivatives) exist.\n",
    "However, $f$ may in principle be arbitrary.\n",
    "It can even be considered to be a \"black box\": for example, $f$ may come from data or from empirical observations.\n",
    "Using exact formulas for integrals involving $f$ is clearly not practical.\n",
    "\n",
    "Therefore, we compute (or approximate) the integrals in the finite element method using **numerical quadrature**.\n",
    "A quadrature formula consists of points $\\{ x_i \\}$ (also called the abscissas) and weights $\\{ w_i \\}$.\n",
    "Then, the integral of a function $F(x)$ is approximated\n",
    "$$\n",
    "    \\int_{-1}^1 F(x) \\, dx \\approx \\sum_{i=1}^N F(x_i) w_i.\n",
    "$$\n",
    "A simple transformation lets us use quadrature to approximate integrals over any interval $[a,b]$.\n",
    "\n",
    "Let $T(x) = \\frac{1}{2}(b-a)(x + 1) + a$.\n",
    "Note that $T : [-1, 1] \\mapsto [a,b]$.\n",
    "Also, $T'(x) = \\frac{1}{2}(b-a)$.\n",
    "\n",
    "Note then that, by change of variables,\n",
    "$$\n",
    "    \\int_a^b F(x) \\, dx = \\int_{-1}^1 F(T(x)) T'(x) \\, dx \\approx \\frac{1}{2}(b-a) \\sum_{i=1}^N F(T(x_i)) w_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the quadrature formula is an approximation, we can talk about its order of accuracy.\n",
    "Let $Q(F,a,b)$ denote the quadrature formula above,\n",
    "$$\n",
    "    Q(F,a,b) = \\frac{1}{2}(b-a) \\sum_{i=1}^N F(T(x_i)) w_i.\n",
    "$$\n",
    "If $h = b - a$, then we expect the quadrature error\n",
    "$$\n",
    "    \\left| \\int_a^b F(x)\\,dx - Q(F,a,b) \\right| \\to 0 \\quad\\text{as}\\quad h \\to 0\n",
    "$$\n",
    "In particular, in many cases, we have $\\left| \\int_a^b F(x)\\,dx - Q(F,a,b) \\right| = \\mathcal{O}(h^\\alpha)$ for some $\\alpha$.\n",
    "Taylor series arguments can be used to find $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a **fixed** interval $[a,b]$, and we want to get increasingly accurate approximations to $\\int_a^b F(x) \\, dx$ using a quadrature formula, we can subdivide the interval into $M$ subintervals, each of length $h = (b-a) / M$.\n",
    "Then, on each subinterval, the error will scale like $h^{\\alpha}$, and so the total error over all intervals will scale like\n",
    "$$\n",
    "    M h^\\alpha = M ((b-a) / M)^\\alpha = (b-a)^\\alpha / M^{\\alpha - 1} = (b-a) h^{\\alpha - 1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most common quadrature formulas, $Q(F,a,b)$ will be **exact** if $F$ is a polynomial of degree $p$ or less (the specific $p$ will depend on the formula).\n",
    "This implies that the quadrature error on an interval of length $h$ will scale like $h^{p + 2}$,(why?) and so, using quadrature and subdivision as described above, the error over a fixed interval will scale like $h^{p+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commonly used quadratures are known as **Gaussian quadratures**.\n",
    "These are quadrature formulas that maximize the **degree of exactness** in terms of polynomial degree.\n",
    "Note that if $n$ points are chosen arbitrarily, then we can come up with a quadrature formula that will integrate polynomials of degree $n - 1$ exactly. (Why?)\n",
    "However, **Gauss-Legendre** formula integrates polynomials of degree $2n - 1$ exactly.\n",
    "The abscissas all lie in the interior of the interval.\n",
    "\n",
    "There are also **Gauss-Radau** and **Gauss-Lobatto** quadratures.\n",
    "Radau quadrature includes one endpoint, and has degree of exactness $2n - 2$.\n",
    "Lobatto quadrature includes both endpoints, and has degree of exactness $2n - 3$.\n",
    "\n",
    "These formulas are closely related to **orthogonal polynomials** and there is a deep and interesting theory of quadrature formulas.\n",
    "For our purposes, we can look up tables of these formulas in textbooks or on Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad_1d(f, a, b):\n",
    "    # Quadrature points in the reference internal\n",
    "    xq_1 = -1/np.sqrt(3)\n",
    "    xq_2 = 1/np.sqrt(3)\n",
    "\n",
    "    h = b - a\n",
    "    x_1 = h*0.5*(xq_1 + 1) + a\n",
    "    x_2 = h*0.5*(xq_2 + 1) + a\n",
    "    return 0.5*h*(f(x_1) + f(x_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               Error         Rate\n",
      "===================================\n",
      "1.0000000000    1.213e-03     ----\n",
      "0.5000000000    1.537e-04     2.98\n",
      "0.2500000000    5.550e-06     4.79\n",
      "0.1250000000    1.741e-07     4.99\n",
      "0.0625000000    5.368e-09     5.02\n",
      "0.0312500000    1.660e-10     5.02\n",
      "0.0156250000    5.156e-12     5.01\n",
      "0.0078125000    1.610e-13     5.00\n",
      "0.0039062500    5.190e-15     4.95\n",
      "0.0019531250    2.424e-16     4.42\n",
      "0.0009765625    1.115e-16     1.12\n",
      "0.0004882812    3.747e-16    -1.75\n",
      "0.0002441406    1.821e-16     1.04\n",
      "0.0001220703    3.629e-17     2.33\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return np.cos(x) * np.exp(np.sin(x))\n",
    "\n",
    "def int_f(x):\n",
    "    # return np.tan(x) - x\n",
    "    return np.exp(np.sin(x))\n",
    "\n",
    "a = 1\n",
    "\n",
    "print(\"h               Error         Rate\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "h_prev = 0\n",
    "error_prev = 0\n",
    "\n",
    "for i in range(14):\n",
    "    h = 2 ** -i\n",
    "    b = a + h\n",
    "    v_exact = int_f(b) - int_f(a)\n",
    "    v_approx = quad_1d(f, a, b)\n",
    "    error = np.abs(v_exact - v_approx)\n",
    "    if h_prev != 0:\n",
    "        rate = \"{: .2f}\".format(np.log(error / error_prev) / np.log(h / h_prev))\n",
    "    else:\n",
    "        rate = \" ----\"\n",
    "    print(\"{:.10f}    {:.3e}    {}\".format(h, error, rate))\n",
    "    error_prev = error\n",
    "    h_prev = h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note:_ the errors decrease at the expected rate, until they reach a level of around $10^{-16}$, at which point round-off error dominates, and the error stagnates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               Error         Rate\n",
      "===================================\n",
      "1.0000000000    1.213e-03     ----\n",
      "0.5000000000    5.438e-05     4.48\n",
      "0.2500000000    3.202e-06     4.09\n",
      "0.1250000000    1.973e-07     4.02\n",
      "0.0625000000    1.229e-08     4.01\n",
      "0.0312500000    7.674e-10     4.00\n",
      "0.0156250000    4.795e-11     4.00\n",
      "0.0078125000    2.997e-12     4.00\n",
      "0.0039062500    1.877e-13     4.00\n",
      "0.0019531250    1.163e-14     4.01\n",
      "0.0009765625    6.106e-16     4.25\n",
      "0.0004882812    2.498e-16     1.29\n",
      "0.0002441406    1.277e-15    -2.35\n",
      "0.0001220703    1.943e-16     2.72\n",
      "0.0000610352    2.276e-15    -3.55\n",
      "0.0000305176    4.996e-16     2.19\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "\n",
    "print(\"h               Error         Rate\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "h_prev = 0\n",
    "error_prev = 0\n",
    "\n",
    "for i in range(16):\n",
    "    M = 2 ** i\n",
    "    h = (b - a) / M\n",
    "\n",
    "    v_exact = int_f(b) - int_f(a)\n",
    "    v_approx = 0.0\n",
    "\n",
    "    a_j = a\n",
    "    for j in range(M):\n",
    "        b_j = a_j + h\n",
    "        v_approx += quad_1d(f, a_j, b_j)\n",
    "        a_j = b_j\n",
    "\n",
    "    error = np.abs(v_exact - v_approx)\n",
    "    if h_prev != 0:\n",
    "        rate = \"{: .2f}\".format(np.log(error / error_prev) / np.log(h / h_prev))\n",
    "    else:\n",
    "        rate = \" ----\"\n",
    "    print(\"{:.10f}    {:.3e}    {}\".format(h, error, rate))\n",
    "    error_prev = error\n",
    "    h_prev = h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
