{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5sMJY4v8Tol"
      },
      "source": [
        "# MTH 651: Advanced Numerical Analysis\n",
        "## Lecture 1\n",
        "\n",
        "### Topics\n",
        "\n",
        "* Class logistics\n",
        "  * Lectures\n",
        "  * Office hours\n",
        "  * Grading\n",
        "  * Text book\n",
        "* Software\n",
        "  * Canvas\n",
        "  * Zulip\n",
        "  * Colab\n",
        "  * Coeus\n",
        "* Course goals and topics\n",
        "* Review of some basic numerical methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Coarse Goals\n",
        "\n",
        "* We are intersted in the **numerical solution** of **partial differential equations**.\n",
        "* We want to use computer algorithms to obtain _approximate_ (i.e. \"numerical\") solutions to PDEs\n",
        "* For the most part, we are interested in PDEs that govern physical systems\n",
        "  * For example: heat transfer, fluid dynamics, electromagnetic, structural mechanics, etc.\n",
        "* Obtaining approximate solutions to these PDEs allows us to **simulate** physical systems, in other\n",
        "  words, we can make predictions about how physical systems will behave without the need to perform\n",
        "  experiments and in situations where calculations done by hand are impossible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Warm-Up and Review of Some Basical Numerical Methods\n",
        "\n",
        "If we want to approximate solutions to differential equations, we should start by approximating\n",
        "derivatives.\n",
        "\n",
        "Let $f$ be a given (smooth) function.\n",
        "\n",
        "Recall the difference quotients:\n",
        "\n",
        "* Forward difference quotient: $$D_F f(x) = \\frac{f(x+h) - f(x)}{h}$$\n",
        "* Backwards difference quotient: $$D_B f(x) = \\frac{f(x) - f(x-h)}{h}$$\n",
        "* Centered difference quotient: $$D_C f(x) = \\frac{f(x+h) - f(x-h)}{2h}$$\n",
        "\n",
        "Each of these **finite difference quotients** approximates the derivative $f'(x)$.\n",
        "\n",
        "**Question:** how accurate are these approximations?\n",
        "\n",
        "<details>\n",
        "<summary><b>Solution:</b></summary>\n",
        "\n",
        "Expand $f(x+h)$ and $f(x-h)$ as Taylor series about the point $x$. Find the remainder after\n",
        "cancelling terms.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do a simple computational example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate our function $f$ and its derivative $f'$ at some sample points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "   return np.sin(2*np.pi*x)\n",
        "\n",
        "def df(x):\n",
        "   return 2*np.pi*np.cos(2*np.pi*x)\n",
        "\n",
        "n = 51 # number of sample points\n",
        "x = np.linspace(0, 1, n)\n",
        "plt.plot(x, f(x), label=\"$f(x) = \\\\sin(2 \\\\pi x)$\")\n",
        "plt.plot(x, df(x), label=\"$f'(x) = 2 \\\\pi \\\\cos(2 \\\\pi x)$\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's compute the forward difference quotient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_F = np.zeros(n)\n",
        "h = x[1]\n",
        "for i in range(n):\n",
        "   xi = i*h\n",
        "   D_F[i] = (f(xi + h) - f(xi)) / h\n",
        "\n",
        "plt.plot(x, df(x), label=\"Exact derivative\")\n",
        "plt.plot(x, D_F, label=\"Forward difference quotient\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_B = np.zeros(n)\n",
        "h = x[1]\n",
        "for i in range(n):\n",
        "   xi = i*h\n",
        "   D_B[i] = (f(xi) - f(xi - h)) / h\n",
        "\n",
        "plt.plot(x, df(x), label=\"Exact derivative\")\n",
        "plt.plot(x, D_B, label=\"Backward difference quotient\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_C = np.zeros(n)\n",
        "h = x[1]\n",
        "for i in range(n):\n",
        "   xi = i*h\n",
        "   D_C[i] = (f(xi + h) - f(xi - h)) / (2*h)\n",
        "\n",
        "plt.plot(x, df(x), label=\"Exact derivative\")\n",
        "plt.plot(x, D_C, label=\"Centered difference quotient\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now try to quantify the error. For simplicitly, we'll estimate $\\sin'(1)$, and vary the step\n",
        "size $h$. Since we know the exact derivative, we can easily compute the error of our approximation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use these values for h\n",
        "h = 2.0 ** np.arange(-1, -10, -1)\n",
        "h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "   return np.sin(x)\n",
        "\n",
        "def df(x):\n",
        "   return np.cos(x)\n",
        "\n",
        "def forward_diff(x, h):\n",
        "   return (f(x+h) - f(x))/h\n",
        "\n",
        "def backward_diff(x, h):\n",
        "   return (f(x) - f(x-h))/h\n",
        "\n",
        "def centered_diff(x, h):\n",
        "   return (f(x+h) - f(x-h))/(2*h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FD = forward_diff(1, h)\n",
        "BD = backward_diff(1, h)\n",
        "CD = centered_diff(1, h)\n",
        "\n",
        "# Compute the error using the exact answer of 1\n",
        "\n",
        "FD_error = np.abs(FD - df(1))\n",
        "BD_error = np.abs(BD - df(1))\n",
        "CD_error = np.abs(CD - df(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "pandas.DataFrame(data=np.transpose([FD_error, BD_error, CD_error]), columns=[\"Forward\", \"Backward\", \"Centered\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is clear from this table that the centered difference quotient is much more accurate. Let's try\n",
        "to numerically confirm the rates we expect.\n",
        "\n",
        "The Taylor series argument showed that the forward and backward difference quotients approximate the\n",
        "first derivative with an error that scales like $\\mathcal{O}(h)$, while the centered difference \n",
        "quotient has an error that scales like $\\mathcal{O}(h^2)$.\n",
        "\n",
        "We chose our step size $h$ to be $h_i = 2^{-i}$ for $i = 1, 2, 3, \\ldots$\n",
        "\n",
        "Let $e_F$ denote the error of the forward difference quotient (i.e. $e_F = | D_F f(x) - f'(x) |$).\n",
        "Then, we know that\n",
        "$$\n",
        "   e_F \\leq ch + \\mathcal{O}(h^2).\n",
        "$$\n",
        "So, for $e_{F,i+1}$ (corresponding to step size $h_{i+1}$) we have\n",
        "$$\n",
        "\\begin{align*}\n",
        "   e_{F,i+1}\n",
        "      &\\leq ch_{i+1} + \\mathcal{O}(h_{i+1}^2) \\\\\n",
        "      &= \\frac{1}{2} c h_i + \\mathcal{O}(h_{i}^2) \\\\\n",
        "      &\\leq \\frac{1}{2} e_{F,i} + \\mathcal{O}(h_{i}^2)\n",
        "\\end{align*}\n",
        "$$\n",
        "which means that halving $h$ should also approximately halve the error (and the ratio of errors\n",
        "will approach $\\frac{1}{2}$ as $h \\to 0$).\n",
        "\n",
        "On the other hand, the centered difference quotient is _second-order accurate_, meaning\n",
        "$$\n",
        "   e_C \\leq c h^2 + \\mathcal{O}(h^3),\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\begin{align*}\n",
        "   e_{C,i+1}\n",
        "      &\\leq ch_{i+1}^2 + \\mathcal{O}(h_{i+1}^3) \\\\\n",
        "      &= \\frac{1}{4} c h_i^2 + \\mathcal{O}(h_{i}^3) \\\\\n",
        "      &\\leq \\frac{1}{4} e_{F,i} + \\mathcal{O}(h_{i}^3),\n",
        "\\end{align*}\n",
        "$$\n",
        "and so halving $h$ should result in a reduction of the error by a factor of 4.\n",
        "\n",
        "More generally, for $e(h) \\sim h^p$ (we would call this a pth-order accurate method), we have $e(rh) \\sim r^p h^p \\sim r^p e(h)$.\n",
        "\n",
        "## Emperical rate of convergence\n",
        "\n",
        "Suppose we have two step sizes, $h_1$ and $h_2$, and we (numerically) compute the errors $e_1$ and\n",
        "$e_2$. We assume that the method has order of accuracy $p$, i.e. $e \\sim h^p$. We will estimate the\n",
        "**rate** $p$ numerically.\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "   \\frac{\n",
        "      \\log\\left( e_1 / e_2 \\right)\n",
        "   }{\n",
        "      \\log\\left( h_1 / h_2 \\right)\n",
        "   }\n",
        "      &\\sim \\frac{\n",
        "         \\log\\left( h_1^p/h_2^p \\right)\n",
        "      }{\n",
        "         \\log\\left( h_1 / h_2 \\right)\n",
        "      } \\\\\n",
        "      &= \\frac{\n",
        "         p \\log\\left( h_1/h_2 \\right)\n",
        "      }{\n",
        "         \\log\\left( h_1 / h_2 \\right)\n",
        "      } \\\\\n",
        "      &= p\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rate(errors, h_ratio):\n",
        "   return np.log(errors[:-1]/errors[1:])/np.log(h_ratio)\n",
        "\n",
        "def prepend_nan(array):\n",
        "   return np.concatenate(([np.NAN], array))\n",
        "\n",
        "pandas.DataFrame(\n",
        "   data=np.transpose([\n",
        "      FD_error, prepend_nan(rate(FD_error, 2)),\n",
        "      BD_error, prepend_nan(rate(FD_error, 2)),\n",
        "      CD_error, prepend_nan(rate(CD_error, 2))\n",
        "   ]),\n",
        "   columns=[\"Forward\", \"Rate\", \"Backward\", \"Rate\", \"Centered\", \"Rate\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another way of seeing the rate (graphically) is to plot the errors on a log-log scale.\n",
        "\n",
        "The error has the form\n",
        "$$\n",
        "e \\sim h^p\n",
        "$$\n",
        "and so\n",
        "$$\n",
        "\\log(e) \\sim \\log(h^p) = p \\log(h)\n",
        "$$\n",
        "and therefore $\\log(e)$ and $\\log(h)$ are linearly related with slope $p$.\n",
        "\n",
        "On a log-log plot, errors of this form will appear linear with slopes corresponding to the rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.loglog(1/h, FD_error, label=\"Forward difference error\")\n",
        "plt.loglog(1/h, BD_error, label=\"Backward difference error\")\n",
        "plt.loglog(1/h, CD_error, label=\"Centered difference error\")\n",
        "plt.xlabel(\"$1/h$\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mth-651",
      "language": "python",
      "name": "mth-651"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
