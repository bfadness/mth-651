{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MTH 651: Advanced Numerical Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lecture 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5sMJY4v8Tol"
      },
      "source": [
        "### Topics\n",
        "\n",
        "* Class logistics\n",
        "  * Lectures\n",
        "  * Office hours\n",
        "  * Grading\n",
        "  * Text book\n",
        "* Software\n",
        "  * Canvas\n",
        "  * Zulip\n",
        "  * Colab\n",
        "  * Coeus\n",
        "* Introductions and background\n",
        "* Course goals and topics\n",
        "* \"Warm up\"\n",
        "  * Review of some basic numerical methods\n",
        "    * Finite difference quotients\n",
        "    * Rates of convergence, empirical rates of convergence\n",
        "    * Finite differences for 1D Poisson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Coarse Goals\n",
        "\n",
        "* We are intersted in the **numerical solution** of **partial differential equations**.\n",
        "* We want to use computer algorithms to obtain _approximate_ (i.e. \"numerical\") solutions to PDEs\n",
        "* For the most part, we are interested in PDEs that govern physical systems\n",
        "  * For example: heat transfer, fluid dynamics, electromagnetic, structural mechanics, etc.\n",
        "* Obtaining approximate solutions to these PDEs allows us to **simulate** physical systems, in other\n",
        "  words, we can make predictions about how physical systems will behave without the need to perform\n",
        "  experiments and in situations where calculations done by hand are impossible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Warm-Up and Review of Some Basical Numerical Methods\n",
        "\n",
        "If we want to approximate solutions to differential equations, we should start by approximating\n",
        "derivatives.\n",
        "\n",
        "Let $f$ be a given (smooth) function.\n",
        "\n",
        "Recall the difference quotients:\n",
        "\n",
        "* Forward difference quotient: $$D_F f(x) = \\frac{f(x+h) - f(x)}{h}$$\n",
        "* Backwards difference quotient: $$D_B f(x) = \\frac{f(x) - f(x-h)}{h}$$\n",
        "* Centered difference quotient: $$D_C f(x) = \\frac{f(x+h) - f(x-h)}{2h}$$\n",
        "\n",
        "Each of these **finite difference quotients** approximates the derivative $f'(x)$.\n",
        "\n",
        "**Question:** how accurate are these approximations?\n",
        "\n",
        "<details>\n",
        "<summary><b>Solution:</b></summary>\n",
        "\n",
        "Expand $f(x+h)$ and $f(x-h)$ as Taylor series about the point $x$. Find the remainder after\n",
        "cancelling terms.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do a simple computational example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate our function $f$ and its derivative $f'$ at some sample points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "   return np.sin(2*np.pi*x)\n",
        "\n",
        "def df(x):\n",
        "   return 2*np.pi*np.cos(2*np.pi*x)\n",
        "\n",
        "n = 51 # number of sample points\n",
        "x = np.linspace(0, 1, n)\n",
        "plt.plot(x, f(x), label=\"$f(x) = \\\\sin(2 \\\\pi x)$\")\n",
        "plt.plot(x, df(x), label=\"$f'(x) = 2 \\\\pi \\\\cos(2 \\\\pi x)$\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's compute the forward difference quotient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_F = np.zeros(n)\n",
        "h = x[1]\n",
        "for i in range(n):\n",
        "   xi = i*h\n",
        "   D_F[i] = (f(xi + h) - f(xi)) / h\n",
        "\n",
        "plt.plot(x, df(x), label=\"Exact derivative\")\n",
        "plt.plot(x, D_F, label=\"Forward difference quotient\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_B = np.zeros(n)\n",
        "h = x[1]\n",
        "for i in range(n):\n",
        "   xi = i*h\n",
        "   D_B[i] = (f(xi) - f(xi - h)) / h\n",
        "\n",
        "plt.plot(x, df(x), label=\"Exact derivative\")\n",
        "plt.plot(x, D_B, label=\"Backward difference quotient\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_C = np.zeros(n)\n",
        "h = x[1]\n",
        "for i in range(n):\n",
        "   xi = i*h\n",
        "   D_C[i] = (f(xi + h) - f(xi - h)) / (2*h)\n",
        "\n",
        "plt.plot(x, df(x), label=\"Exact derivative\")\n",
        "plt.plot(x, D_C, label=\"Centered difference quotient\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now try to quantify the error. For simplicitly, we'll estimate $\\sin'(1)$, and vary the step\n",
        "size $h$. Since we know the exact derivative, we can easily compute the error of our approximation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use these values for h\n",
        "h = 2.0 ** np.arange(-1, -10, -1)\n",
        "h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "   return np.sin(x)\n",
        "\n",
        "def df(x):\n",
        "   return np.cos(x)\n",
        "\n",
        "def forward_diff(x, h):\n",
        "   return (f(x+h) - f(x))/h\n",
        "\n",
        "def backward_diff(x, h):\n",
        "   return (f(x) - f(x-h))/h\n",
        "\n",
        "def centered_diff(x, h):\n",
        "   return (f(x+h) - f(x-h))/(2*h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FD = forward_diff(1, h)\n",
        "BD = backward_diff(1, h)\n",
        "CD = centered_diff(1, h)\n",
        "\n",
        "# Compute the error using the exact answer of 1\n",
        "\n",
        "FD_error = np.abs(FD - df(1))\n",
        "BD_error = np.abs(BD - df(1))\n",
        "CD_error = np.abs(CD - df(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "pandas.DataFrame(data=np.transpose([FD_error, BD_error, CD_error]), columns=[\"Forward\", \"Backward\", \"Centered\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is clear from this table that the centered difference quotient is much more accurate. Let's try\n",
        "to numerically confirm the rates we expect.\n",
        "\n",
        "The Taylor series argument showed that the forward and backward difference quotients approximate the\n",
        "first derivative with an error that scales like $\\mathcal{O}(h)$, while the centered difference \n",
        "quotient has an error that scales like $\\mathcal{O}(h^2)$.\n",
        "\n",
        "We chose our step size $h$ to be $h_i = 2^{-i}$ for $i = 1, 2, 3, \\ldots$\n",
        "\n",
        "Let $e_F$ denote the error of the forward difference quotient (i.e. $e_F = | D_F f(x) - f'(x) |$).\n",
        "Then, we know that\n",
        "$$\n",
        "   e_F \\leq ch + \\mathcal{O}(h^2).\n",
        "$$\n",
        "So, for $e_{F,i+1}$ (corresponding to step size $h_{i+1}$) we have\n",
        "$$\n",
        "\\begin{align*}\n",
        "   e_{F,i+1}\n",
        "      &\\leq ch_{i+1} + \\mathcal{O}(h_{i+1}^2) \\\\\n",
        "      &= \\frac{1}{2} c h_i + \\mathcal{O}(h_{i}^2) \\\\\n",
        "      &\\leq \\frac{1}{2} e_{F,i} + \\mathcal{O}(h_{i}^2)\n",
        "\\end{align*}\n",
        "$$\n",
        "which means that halving $h$ should also approximately halve the error (and the ratio of errors\n",
        "will approach $\\frac{1}{2}$ as $h \\to 0$).\n",
        "\n",
        "On the other hand, the centered difference quotient is _second-order accurate_, meaning\n",
        "$$\n",
        "   e_C \\leq c h^2 + \\mathcal{O}(h^3),\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\begin{align*}\n",
        "   e_{C,i+1}\n",
        "      &\\leq ch_{i+1}^2 + \\mathcal{O}(h_{i+1}^3) \\\\\n",
        "      &= \\frac{1}{4} c h_i^2 + \\mathcal{O}(h_{i}^3) \\\\\n",
        "      &\\leq \\frac{1}{4} e_{F,i} + \\mathcal{O}(h_{i}^3),\n",
        "\\end{align*}\n",
        "$$\n",
        "and so halving $h$ should result in a reduction of the error by a factor of 4.\n",
        "\n",
        "More generally, for $e(h) \\sim h^p$ (we would call this a pth-order accurate method), we have $e(rh) \\sim r^p h^p \\sim r^p e(h)$.\n",
        "\n",
        "## Emperical rate of convergence\n",
        "\n",
        "Suppose we have two step sizes, $h_1$ and $h_2$, and we (numerically) compute the errors $e_1$ and\n",
        "$e_2$. We assume that the method has order of accuracy $p$, i.e. $e \\sim h^p$. We will estimate the\n",
        "**rate** $p$ numerically.\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "   \\frac{\n",
        "      \\log\\left( e_1 / e_2 \\right)\n",
        "   }{\n",
        "      \\log\\left( h_1 / h_2 \\right)\n",
        "   }\n",
        "      &\\sim \\frac{\n",
        "         \\log\\left( h_1^p/h_2^p \\right)\n",
        "      }{\n",
        "         \\log\\left( h_1 / h_2 \\right)\n",
        "      } \\\\\n",
        "      &= \\frac{\n",
        "         p \\log\\left( h_1/h_2 \\right)\n",
        "      }{\n",
        "         \\log\\left( h_1 / h_2 \\right)\n",
        "      } \\\\\n",
        "      &= p\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rate(errors, h_ratio):\n",
        "   return np.log(errors[:-1]/errors[1:])/np.log(h_ratio)\n",
        "\n",
        "def prepend_nan(array):\n",
        "   return np.concatenate(([np.NAN], array))\n",
        "\n",
        "df = pandas.DataFrame(\n",
        "   data=np.transpose([\n",
        "      FD_error, prepend_nan(rate(FD_error, 2)),\n",
        "      BD_error, prepend_nan(rate(FD_error, 2)),\n",
        "      CD_error, prepend_nan(rate(CD_error, 2))\n",
        "   ]),\n",
        "   columns=[\"Forward\", \"Rate\", \"Backward\", \"Rate\", \"Centered\", \"Rate\"]\n",
        ")\n",
        "df.style.format(na_rep=\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another way of seeing the rate (graphically) is to plot the errors on a log-log scale.\n",
        "\n",
        "The error has the form\n",
        "$$\n",
        "e \\sim h^p\n",
        "$$\n",
        "and so\n",
        "$$\n",
        "\\log(e) \\sim \\log(h^p) = p \\log(h)\n",
        "$$\n",
        "and therefore $\\log(e)$ and $\\log(h)$ are linearly related with slope $p$.\n",
        "\n",
        "On a log-log plot, errors of this form will appear linear with slopes corresponding to the rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.loglog(1/h, FD_error, label=\"Forward difference error\")\n",
        "plt.loglog(1/h, BD_error, label=\"Backward difference error\")\n",
        "plt.loglog(1/h, CD_error, label=\"Centered difference error\")\n",
        "plt.xlabel(\"$1/h$\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using finite differences to solve a Poisson problem\n",
        "\n",
        "We will often be interested in the following **model problem**.\n",
        "\n",
        "Consider Laplace's equation\n",
        "$$\n",
        "-\\Delta u = 0\n",
        "$$\n",
        "where $\\Delta$ is the Laplacian $\\sum_{i=1}^d \\dfrac{\\partial^2}{\\partial x_i^2}$.\n",
        "\n",
        "More generally we consider the **Poisson problem**\n",
        "$$\n",
        "-\\Delta u = f\n",
        "$$\n",
        "in the domain $\\Omega \\subseteq \\mathbb{R}^d$ subject to the appropriate boundary conditions on $\\partial\\Omega$.\n",
        "\n",
        "For now, let's consider the 1D problem with $\\Omega = [0,1]$,\n",
        "$$\\begin{equation} \\tag{$*$}\n",
        "\\left\\{\n",
        "   \\begin{aligned}\n",
        "      -u''(x) &= f \\\\\n",
        "      u(0) &= 0 \\\\\n",
        "      u(1) &= 0\n",
        "   \\end{aligned}\n",
        "\\right.\n",
        "\\end{equation}$$\n",
        "with **homogeneous Dirichlet boundary conditions**.\n",
        "\n",
        "We can formulate a simple _finite difference_ method to solve this problem.\n",
        "\n",
        "Consider $N + 1$ grid points with spacing $h$, i.e.\n",
        "$$\n",
        "   x_i = ih, \\qquad i = 0, 1, \\ldots, N.\n",
        "$$\n",
        "Then, we _discretize_ $(*)$ by replacing the derivatives with finite difference quotients.\n",
        "\n",
        "In particular, consider the centered finite difference quotient approximating the second derivative,\n",
        "$$\n",
        "   f''(x) \\approx D^2 f(x) := \\frac{f(x-h) - 2 f(x) + f(x+h)}{h^2}\n",
        "$$\n",
        "\n",
        "Then, a discretization of $(*)$ could be given by\n",
        "$$\n",
        "\\left\\{\n",
        "   \\begin{aligned}\n",
        "      u_0 &= 0\\\\\n",
        "      u_N &= 0\\\\\n",
        "      -D^2 u_i &= f(x_i) \\qquad \\text{for $1 \\leq i \\leq N-1$}\n",
        "   \\end{aligned}\n",
        "\\right.\n",
        "$$\n",
        "where\n",
        "$$\n",
        "   D^2 u_i := \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2}.\n",
        "$$\n",
        "\n",
        "After picking the number of grid points $N$, this will result in a _linear system of equations_ to solve for the approximate solution $u_i$ at each point. The system will take the form\n",
        "\n",
        "$$\n",
        "   \\frac{1}{h^2}\n",
        "   \\begin{pmatrix}\n",
        "       1 &  \\cdot &  \\cdot &  \\cdot & \\cdots & \\cdot & \\cdot & \\cdot & \\cdot\\\\\n",
        "      -1 &  2 & -1 &  \\cdot & \\cdots & \\cdot & \\cdot & \\cdot & \\cdot\\\\\n",
        "       \\cdot & -1 &  2 & -1 & \\cdots & \\cdot & \\cdot & \\cdot & \\cdot\\\\\n",
        "      \\vdots & \\vdots & \\vdots & \\vdots & \\ddots &   \\\\\n",
        "      \\cdot & \\cdot & \\cdot & \\cdot & \\cdots & \\cdot & -1 & 2 & -1 \\\\\n",
        "      \\cdot & \\cdot & \\cdot & \\cdot & \\cdots & \\cdot & \\cdot & \\cdot &  1 \n",
        "   \\end{pmatrix}\n",
        "   \\begin{pmatrix}\n",
        "      u_0 \\\\ u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_{N-1} \\\\ u_N\n",
        "   \\end{pmatrix}\n",
        "   =\n",
        "   \\begin{pmatrix}\n",
        "      0 \\\\ f(x_1) \\\\ f(x_2) \\\\ \\vdots \\\\ f(x_{N-1}) \\\\ 0\n",
        "   \\end{pmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Simple Poisson solver in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_grid(N):\n",
        "   return np.linspace(0, 1, N+1)\n",
        "\n",
        "def make_poisson_matrix(N):\n",
        "   A = np.zeros((N+1, N+1))\n",
        "   # Boundary conditions\n",
        "   A[0,0] = 1.0 # First row/column\n",
        "   A[-1,-1] = 1.0 # Last row/column\n",
        "   # Difference quotients\n",
        "   for i in range(1, N):\n",
        "      A[i,i-1] = -1\n",
        "      A[i,i] = 2\n",
        "      A[i,i+1] = -1\n",
        "   h = 1.0 / N\n",
        "   A /= h*h\n",
        "   return A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's pick the right-hand side $f(x) = (2 \\pi)^2 \\sin(2 \\pi x)$. It is easy to verify that the exact solution to this problem is $u(x) = \\sin(2 \\pi x)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "   return ((2*np.pi)**2)*np.sin(2*np.pi*x)\n",
        "\n",
        "def solve_poisson(N):\n",
        "   x = make_grid(N)\n",
        "   b = f(x)\n",
        "   A = make_poisson_matrix(N)\n",
        "   u = np.linalg.solve(A, b)\n",
        "   return u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the solution to visually verify that it looks as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(make_grid(20), solve_poisson(20), marker=\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This looks roughly like what we would expect.\n",
        "\n",
        "Let's calculate the error numerically using our knowledge of the exact solution.\n",
        "\n",
        "We will calculate the $\\ell_\\infty$ error,\n",
        "$$\n",
        "e = \\max_i | u_i - u(x_i) |\n",
        "$$\n",
        "where $u$ is the exact solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def poisson_error(N):\n",
        "   return np.max(np.abs(solve_poisson(N) - np.sin(2*np.pi*make_grid(N))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute the rate of convergence as discussed above. We will estimate\n",
        "$$\n",
        "\\text{rate} \\approx \\frac{\\log(e_1/e_2)}{\\log(h_1/h_2)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rate(N):\n",
        "   e1 = poisson_error(N)\n",
        "   e2 = poisson_error(2*N)\n",
        "   return np.log(e1/e2) / np.log(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[rate(10), rate(20), rate(40), rate(80), rate(160)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we could have guessed, this method is converging with **second-order accuracy**.\n",
        "\n",
        "A simple Taylor series argument would show that\n",
        "$$\n",
        "   | u''(x) - D^2 u(x) | = \\mathcal{O}(h^2),\n",
        "$$\n",
        "so this is expected behavior.\n",
        "\n",
        "**But**, we haven't given a rigorous proof that our finite difference method will really converge to the exact solution of the differential equation with second-order accuracy (only that the _consistency error_ is second-order)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next time: finite elements for the same problem\n",
        "\n",
        "This discussion on finite differences was intended as a warm-up to familiarize ourselves with simple model problem, recall the notions of accuracy and order of convergence, and perform some basic computaitons.\n",
        "\n",
        "However, the focus of this course will not be on finite difference methods, but rather **finite element methods**. This approach will have **many similiarities** with the finite difference method, but also some **important (practical and philosophical) differences**.\n",
        "\n",
        "Using finite element methods will help us:\n",
        "\n",
        "* Understand, analyze, and prove accuracy and other properties of our discretization in a systematic way\n",
        "* Easily translate mathematical equations into discretizations that can be solved on the computer\n",
        "* Handle complicated geometries in multiple dimensions (unstructured meshes)\n",
        "* Incorporate adaptivity\n",
        "* \"Mimic\" important properties of the equations (conservation, etc.)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "5d4853bb342ce7457c0db7bc3c20704bcd1a1a8949792637a85013d5ddbd2d6f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
